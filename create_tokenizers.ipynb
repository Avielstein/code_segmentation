{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/sentencepiece/\n",
    "#http://ethen8181.github.io/machine-learning/deep_learning/subword/bpe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from tqdm import tqdm #inline progress bar (quality of life)\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move data to location for analizing\n",
    "def make_data(file):\n",
    "    # open file in read mode\n",
    "    number_of_lines = 0\n",
    "    num_chars = 0 #TODO\n",
    "    with open(file, 'r') as read_obj:\n",
    "        print('loading data from ',file,'...')\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # Iterate over each row in the csv using reader object\n",
    "\n",
    "        data = []\n",
    "        for row in tqdm(csv_reader):\n",
    "            try:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                #row[0] - code\n",
    "                #row[1] - comment\n",
    "\n",
    "                number_of_lines+=row[0].count('\\n')\n",
    "\n",
    "                #way to handle white spaces:\n",
    "                #space #do first, \n",
    "                new_code = row[0].replace(' ',' SPACE')\n",
    "                #newline\n",
    "                new_code = new_code.replace('\\n',' NEWLINE')\n",
    "                #tab\n",
    "                new_code = new_code.replace('\\t',' TAB')\n",
    "\n",
    "                #TODO\n",
    "                #FILTER FOR UNICODE THING\n",
    "\n",
    "\n",
    "                #save new data\n",
    "                \n",
    "                #both code and comment\n",
    "                row = [new_code,row[1]]\n",
    "                \n",
    "                data.append(row)\n",
    "\n",
    "            #https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte\n",
    "            #https://intellipaat.com/community/18827/how-to-delete-only-one-row-in-csv-with-python\n",
    "            except:\n",
    "                csv_reader.remove(row)\n",
    "\n",
    "\n",
    "        read_obj.close()\n",
    "\n",
    "    print('num samples: ', len(data))\n",
    "    print('num lines: ', number_of_lines)\n",
    "    \n",
    "    return data,number_of_lines\n",
    "\n",
    "def save_data(data):\n",
    "    with open('data.txt', 'w') as filehandle:\n",
    "        for i in tqdm(range(len(data))):\n",
    "            filehandle.write('%s\\n' % data[i][0])\n",
    "            \n",
    "            \n",
    "class Tokenizer:\n",
    "\n",
    "    #def __init__(self, filepath='python_tokenizer.model'):\n",
    "    def __init__(self, filepath):\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=filepath)\n",
    "\n",
    "    def encode(self, text, t=int):\n",
    "        return self.sp.encode(text, out_type=t)\n",
    "\n",
    "    def decode(self, pieces):\n",
    "        return self.sp.decode(pieces)\n",
    "\n",
    "    @staticmethod\n",
    "    def train(input_file='data/raw_sents.txt', model_prefix='sp_model', vocab_size=30522,number_of_lines=10000):\n",
    "        spm.SentencePieceTrainer.train(input=input_file, model_prefix=model_prefix, vocab_size=vocab_size,\n",
    "                                       #input_sentence_size=2 ** 16, shuffle_input_sentence=True)\n",
    "                                       input_sentence_size=number_of_lines, shuffle_input_sentence=True)\n",
    "        \n",
    "        \n",
    "#TRAIN A TOKENIZER\n",
    "def train_tokenizer(name):\n",
    "    #get data\n",
    "    file = 'code-comment-'+name+'.csv'\n",
    "    data, number_of_lines = make_data(file)\n",
    "    save_data(data)\n",
    "\n",
    "    #train\n",
    "    Tokenizer.train(input_file='data.txt', model_prefix=name+'_tokenizer', vocab_size=10000, number_of_lines=number_of_lines) #model_prefix is model storage name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang='py'\n",
    "#lang='cpp'\n",
    "lang='java'\n",
    "#lang='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21608it [00:00, 216078.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... py short\n",
      "loading data from  code-comment-short_py.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384274it [00:01, 222010.64it/s]\n",
      " 35%|███▍      | 133479/384274 [00:00<00:00, 1334778.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  384274\n",
      "num lines:  1379956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384274/384274 [00:00<00:00, 1333802.81it/s]\n",
      "30040it [00:00, 147329.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... py medium\n",
      "loading data from  code-comment-medium_py.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1090472it [00:07, 152365.00it/s]\n",
      " 16%|█▋        | 177371/1090472 [00:00<00:01, 885453.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  1090472\n",
      "num lines:  6496023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090472/1090472 [00:01<00:00, 841240.25it/s]\n",
      "6976it [00:00, 69757.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... py long\n",
      "loading data from  code-comment-long_py.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355397it [00:04, 77217.66it/s]\n",
      " 15%|█▌        | 53366/355397 [00:00<00:00, 533654.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  355397\n",
      "num lines:  4717632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355397/355397 [00:00<00:00, 494003.61it/s]\n",
      "45681it [00:00, 217830.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... cpp short\n",
      "loading data from  code-comment-short_cpp.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1579746it [00:06, 243431.72it/s]\n",
      " 16%|█▌        | 255899/1579746 [00:00<00:01, 1272512.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  1579746\n",
      "num lines:  2593695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1579746/1579746 [00:01<00:00, 1340261.45it/s]\n",
      "12873it [00:00, 128722.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... cpp medium\n",
      "loading data from  code-comment-medium_cpp.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "648940it [00:04, 135410.09it/s]\n",
      " 13%|█▎        | 81244/648940 [00:00<00:00, 812438.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  648940\n",
      "num lines:  3623966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648940/648940 [00:00<00:00, 784037.38it/s]\n",
      "15037it [00:00, 74968.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... cpp long\n",
      "loading data from  code-comment-long_cpp.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161779it [00:02, 78422.70it/s]\n",
      " 32%|███▏      | 51949/161779 [00:00<00:00, 519463.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  161779\n",
      "num lines:  2203111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161779/161779 [00:00<00:00, 529823.54it/s]\n",
      "51457it [00:00, 249726.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... java short\n",
      "loading data from  code-comment-short_java.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2234085it [00:08, 256416.36it/s]\n",
      "  7%|▋         | 148340/2234085 [00:00<00:01, 1483383.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  2234085\n",
      "num lines:  5200971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2234085/2234085 [00:01<00:00, 1511671.06it/s]\n",
      "28001it [00:00, 140260.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... java medium\n",
      "loading data from  code-comment-medium_java.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1030612it [00:07, 138948.89it/s]\n",
      "  8%|▊         | 79099/1030612 [00:00<00:01, 790958.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  1030612\n",
      "num lines:  5912465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1030612/1030612 [00:01<00:00, 831215.26it/s]\n",
      "13408it [00:00, 66679.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... java long\n",
      "loading data from  code-comment-long_java.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281307it [00:03, 71926.38it/s]\n",
      " 18%|█▊        | 51207/281307 [00:00<00:00, 512064.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  281307\n",
      "num lines:  3757412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281307/281307 [00:00<00:00, 476286.95it/s]\n",
      "47671it [00:00, 240130.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... all short\n",
      "loading data from  code-comment-short_all.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4198103it [00:16, 248348.42it/s]\n",
      "  3%|▎         | 137191/4198103 [00:00<00:02, 1371898.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  4198103\n",
      "num lines:  9174622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4198103/4198103 [00:03<00:00, 1383857.86it/s]\n",
      "15952it [00:00, 159509.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... all medium\n",
      "loading data from  code-comment-medium_all.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2770022it [00:17, 160578.02it/s]\n",
      "  3%|▎         | 93199/2770022 [00:00<00:02, 931982.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  2770022\n",
      "num lines:  16032454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2770022/2770022 [00:03<00:00, 909118.78it/s]\n",
      "15095it [00:00, 73538.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing... all long\n",
      "loading data from  code-comment-long_all.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "798481it [00:10, 78555.88it/s]\n",
      "  4%|▍         | 33511/798481 [00:00<00:02, 335087.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  798481\n",
      "num lines:  10678155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 798481/798481 [00:01<00:00, 480101.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in ['py','cpp','java','all']:\n",
    "    for j in ['short','medium','long']:\n",
    "        print('trianing...',i,j)\n",
    "        train_tokenizer(j+'_'+i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int  FREAK_Impl::descriptorSize()  const \n",
      "{ \n",
      "        return  FREAK_NB_PAIRS  /  8;  //  descriptor  length  in  bytes \n",
      "} \n",
      "\n",
      "('▁int', 1209)\n",
      "('▁SPACE', 3)\n",
      "('FR', 2518)\n",
      "('E', 27)\n",
      "('AK', 2228)\n",
      "('_', 5)\n",
      "('Impl', 724)\n",
      "('::', 18)\n",
      "('descriptor', 1948)\n",
      "('Size', 156)\n",
      "('()', 20)\n",
      "('▁SPACEconst', 19)\n",
      "('▁NEWLINE', 4)\n",
      "('{', 13)\n",
      "('▁NEWLINE', 4)\n",
      "('▁SPACE', 3)\n",
      "('▁SPACE', 3)\n",
      "('▁SPACE', 3)\n",
      "('▁SPACEreturn', 24)\n",
      "('▁SPACE', 3)\n",
      "('FR', 2518)\n",
      "('E', 27)\n",
      "('AK', 2228)\n",
      "('_', 5)\n",
      "('NB', 1924)\n",
      "('_', 5)\n",
      "('PA', 2238)\n",
      "('IR', 1152)\n",
      "('S', 58)\n",
      "('▁SPACE', 3)\n",
      "('/', 92)\n",
      "('▁SPACE', 3)\n",
      "('8;', 923)\n",
      "('▁SPACE', 3)\n",
      "('//', 117)\n",
      "('▁SPACEdescriptor', 1689)\n",
      "('▁SPACElength', 434)\n",
      "('▁SPACEin', 80)\n",
      "('▁SPACEbytes', 449)\n",
      "('▁NEWLINE', 4)\n",
      "('}', 14)\n",
      "('▁NEWLINE', 4)\n"
     ]
    }
   ],
   "source": [
    "#ues examples\n",
    "\n",
    "#detokenize\n",
    "def decode_tokenized_code_snippet(tokens):\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    #decode but still has the added strings\n",
    "    #print(decoded)\n",
    "    token_string = ''.join(decoded)\n",
    "    token_string = token_string.replace('SPACE',' ')\n",
    "    token_string = token_string.replace('NEWLINE','\\n')\n",
    "    token_string = token_string.replace('TAB','\\t')\n",
    "    #print(token_string)\n",
    "    return token_string\n",
    "\n",
    "#instantiate tokenizer model\n",
    "tokenizer = Tokenizer(lang+'_tokenizer.model')\n",
    "\n",
    "example_code = data[1][0]\n",
    "#tokenize code (ie encode)\n",
    "#with words\n",
    "tokens= tokenizer.encode(data[1][0],t=str)\n",
    "#with numbers\n",
    "tokens_nums = tokenizer.encode(example_code)\n",
    "print(decode_tokenized_code_snippet(tokens))\n",
    "\n",
    "for i in zip(tokens,tokens_nums):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "a = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
