{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a program from google code jam\n",
    "#load segmentation LSTM\n",
    "#process program to be read by LSTM\n",
    "#use LSTM to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "import random as ra\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from code segmentation file\n",
    "\n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self, filepath='python_tokenizer_30k.model'):\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=filepath)\n",
    "\n",
    "    def encode(self, text, t=int):\n",
    "        return self.sp.encode(text, out_type=t)\n",
    "\n",
    "    def decode(self, pieces):\n",
    "        return self.sp.decode(pieces)\n",
    "\n",
    "    @staticmethod\n",
    "    def train(input_file='data/raw_sents.txt', model_prefix='sp_model', vocab_size=30522):\n",
    "        spm.SentencePieceTrainer.train(input=input_file, model_prefix=model_prefix, vocab_size=vocab_size,\n",
    "                                       #input_sentence_size=2 ** 16, shuffle_input_sentence=True)\n",
    "                                       input_sentence_size=number_of_lines, shuffle_input_sentence=True)\n",
    "        \n",
    "        #instantiate tokenizer model\n",
    "tokenizer = Tokenizer('python_tokenizer.model')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "# adapted from the PyTorch examples. for the full PyTorch LM example, see: \n",
    "# https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n",
    "###\n",
    "class LSTM_LM(nn.Module):\n",
    "    \"\"\"Model feeds pre-trained embeddings through a series of biLSTM\n",
    "       layers, followed by a linear vocabulary decoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim, lstm_layers, word_vectors, \n",
    "                 dropout=0.05, bidirectional = True):\n",
    "        super(LSTM_LM, self).__init__()\n",
    "\n",
    "        self.vocab_size = word_vectors.shape[0]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm_layers = lstm_layers\n",
    "\n",
    "        # blank embed layer starting from GloVe pre-trained vectors\n",
    "        self._embed = nn.Embedding.from_pretrained(word_vectors, freeze=False)        \n",
    "        self._drop = nn.Dropout(dropout)\n",
    "\n",
    "        self._lstm = nn.LSTM(in_dim, hidden_dim, num_layers = lstm_layers, dropout = dropout,\n",
    "                             bidirectional = bidirectional, batch_first=True)\n",
    "        self._ReLU = nn.ReLU()\n",
    "        self._pred = nn.Linear((2 if bidirectional else 1)*hidden_dim, \n",
    "                               #self.vocab_size)\n",
    "                               1) #only 1 or zeros here \n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self._drop(self._embed(x))\n",
    "        z, h = self._lstm(e)\n",
    "        z_drop = self._drop(z)\n",
    "        s = self._pred(self._ReLU(z_drop))\n",
    "        #s = s.view(-1, self.vocab_size)\n",
    "        s = s.squeeze()\n",
    "        return s, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        return weight.new_zeros(self.lstm_layers, batch_size, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_LM(\n",
       "  (_embed): Embedding(10000, 256)\n",
       "  (_drop): Dropout(p=0.05, inplace=False)\n",
       "  (_lstm): LSTM(256, 200, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  (_ReLU): ReLU()\n",
       "  (_pred): Linear(in_features=400, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########\n",
    "## use saved model\n",
    "#######\n",
    "\n",
    "torch.manual_seed(691)\n",
    "\n",
    "#vocab size from sentence peice\n",
    "#vocab dim???? \n",
    "vocab_size = 10000 #same as sentence peice\n",
    "vocab_dim = 50  # the size of our pre-trained word vectors\n",
    "\n",
    "# randomly initialize our word vectors!\n",
    "vocab_dim = 256\n",
    "word_vectors = torch.randn(vocab_size, vocab_dim)\n",
    "word_vectors.shape, word_vectors\n",
    "\n",
    "#set up model\n",
    "hidden_dim = 200\n",
    "lstm_layers = 2\n",
    "LSTM_LM_net_trained = LSTM_LM(word_vectors.shape[1], hidden_dim,lstm_layers, word_vectors)\n",
    "\n",
    "#[TODO]: fix so it works\n",
    "#https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "#https://stackoverflow.com/questions/61242966/pytorch-attributeerror-function-object-has-no-attribute-copy\n",
    "\n",
    "#load weights into model\n",
    "LSTM_LM_net_trained.load_state_dict(torch.load('biLSTM_LM.pt'))\n",
    "LSTM_LM_net_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to\n",
    "# demonstrate readlines()\n",
    "#get all python files and associated task\n",
    "def get_GCJ_code():\n",
    "    path = 'example.py'\n",
    "    code = ''\n",
    "    # Using readlines()\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    " \n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        code+=line\n",
    "    return code\n",
    "\n",
    "#get_GCJ_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_sliding_window(token_list, window_diamiter,encode=False,PAD='unk'):\n",
    "    windows = []\n",
    "    for i in range(len(token_list)):\n",
    "        \n",
    "        #print(token_list)\n",
    "        #input()\n",
    "        \n",
    "        window = []\n",
    "        \n",
    "        #if we have to pad the begining\n",
    "        if i < window_diamiter:\n",
    "            before_len = window_diamiter-i\n",
    "            before = [PAD]*before_len+token_list[0:i]\n",
    "        else:\n",
    "            before = token_list[i-window_diamiter:i]\n",
    "        \n",
    "        #if we have to pad the end\n",
    "        if i+window_diamiter>=len(token_list):\n",
    "            after_len = (i+1+window_diamiter)-len(token_list)\n",
    "            after = token_list[i+1:i+1+window_diamiter]+[PAD]*after_len\n",
    "\n",
    "        else:\n",
    "            after = token_list[i+1:i+1+window_diamiter]\n",
    "        \n",
    "        #put it togeather\n",
    "        #print('------')\n",
    "        #print('before:',before)\n",
    "        #print('center:',token_list[i])\n",
    "        #print('after:',after)\n",
    "        window = before + [token_list[i]] + after\n",
    "        #for encoding code if we want\n",
    "        if encode:\n",
    "            new_window = []\n",
    "            #print(window)\n",
    "            #input()\n",
    "            for i in window:\n",
    "                encoded = tokenizer.encode(i)\n",
    "                if len(encoded)>1:       \n",
    "                    x=encoded[1]\n",
    "                    if type(x)==list:\n",
    "                        new_window.append(x[0])\n",
    "                    else:\n",
    "                        new_window.append(x)\n",
    "                elif len(encoded)==1:\n",
    "                    if type(encoded)==list:\n",
    "                        new_window.append(encoded[0])\n",
    "                    else:\n",
    "                        new_window.append(encoded)\n",
    "                else:\n",
    "                    #for some reason it finds the unicode stuff __\n",
    "                    pass\n",
    "                    #print(window)\n",
    "                    #print(i)\n",
    "                    #print(encoded)\n",
    "                    #input()\n",
    "            #print(window)\n",
    "            #print(len(window))\n",
    "            #print(len(tokenizer.decode(window)))\n",
    "            #print(tokenizer.decode(window))\n",
    "            #print(len(tokenizer.encode(window)))\n",
    "            #window = tokenizer.encode(tokenizer.decode(window))\n",
    "            window = new_window\n",
    "        #print(window)\n",
    "        #print(len(window))\n",
    "        #input()\n",
    "\n",
    "        #save windowz\n",
    "        windows.append(window)\n",
    "    \n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#NOTE, THIS ONLY GETS THE PREDICTED BREAK POINTS FROM A PREDICTION\n",
    "#WITH THE NEWLINE TOKEN AT CENTER OF WINDOW\n",
    "def get_predicted_break_points(code_windows, model):\n",
    "    start = 0\n",
    "    code  =[]\n",
    "    break_points = []\n",
    "    print(len(code_windows))\n",
    "    for window_i in range(len(code_windows)):\n",
    "        #get window, which has our tokens\n",
    "        window = code_windows[window_i]\n",
    "        window_predictions = get_window_predictions(window,model)\n",
    "        #mid = math.ceil(len(window)/2)\n",
    "        mid = int(len(window)/2) #actually we need to round down...\n",
    "        mid_token = tokenizer.decode(int(window[mid]))\n",
    "        mid_pred = window_predictions[mid]\n",
    "        if mid_token[-7:]=='NEWLINE':\n",
    "            if round(mid_pred) == 1:\n",
    "                break_points.append(window_i)\n",
    "                \n",
    "                \n",
    "        code.append(mid_token)\n",
    "        start+=1\n",
    "    return code, break_points\n",
    "    \n",
    "#code_windows = segments['0']['x']\n",
    "#code, breaks = get_predicted_break_points(code_windows,LSTM_LM_net_trained)\n",
    "#print(breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all predictions from one window\n",
    "def get_window_predictions(window, model):\n",
    "    preds, h = model(torch.tensor([window]))\n",
    "    preds = torch.flatten(torch.sigmoid(preds))\n",
    "    preds = preds.detach().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from code segmentation file\n",
    "def insert_comments(code, break_spots, comment='\\n'+'*'*8+'\\n',at_begining=True):\n",
    "    #if there is a a comment at begining of snippet\n",
    "    if at_begining:\n",
    "        #adds a notation to add a 0\n",
    "        #at beigning of break spots too\n",
    "        break_spots.insert(0,0)\n",
    "    \n",
    "    #go through breaks backwards\n",
    "    #so as not to mess up break \n",
    "    #spots as we would if we went forward\n",
    "    for b in break_spots[::-1]:\n",
    "        code.insert(b,comment)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2402\n",
      "\n",
      "********\n",
      "import streamlit as st\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "from utils import db_utils, MycoDetectContam as detect\n",
      "from PIL import Image\n",
      "import os, time\n",
      "\n",
      "def run(device_name=None):\n",
      "\n",
      "\tif device_name=None:\n",
      "\t\tst.title(device_name)\n",
      "\n",
      "\t\t#get data on open\n",
      "\t\t#if 'device_state' not in st.session_state:\n",
      "\t\t#\tst.session_state['device_state'] = db_utils.get_device_data_from_firebase(device_name)\n",
      "\n",
      "\t\t#get new data if there is any\n",
      "\t\t#https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-without-exceptions\n",
      "\t\tfrom pathlib import Path\n",
      "\t\tinbox = Path('inbox/'+st.session_state.user['localId']+'.txt')\n",
      "\t\tif inbox.is_file():\n",
      "\t\t\tprint('got update')\n",
      "\t\t\t#dete once checked\n",
      "\t\t\t#https://amiradata.com/python-delete-files-and-directories/\n",
      "\t\t\tinbox.unlink()\n",
      "\n",
      "********\n",
      "\n",
      "\t\t\t#get new data\n",
      "\t\t\tst.session_state['device_state'] = db_utils.get_device_data_from_firebase(device_name)\n",
      "\n",
      "\t\telse:\n",
      "\t\t\tprint('no update')\n",
      "\n",
      "\t\t#get image if there is a new one\n",
      "\t\tif st.session_state.device_state['new_image']=='1':\n",
      "\t\t\tprint('got image')\n",
      "\t\t\tdb_utils.get_image(device_name)\n",
      "\n",
      "\t\t#reference to image / see if one exists\n",
      "\t\ttry:\n",
      "\t\t\tpath = 'media/'+st.session_state.user['localId']+'/'+device_name+'.jpg'\n",
      "\t\t\timage = Image.open(path)\n",
      "\t\texcept:\n",
      "\t\t\tpath = 'media/no_image.jpeg'\n",
      "\t\t\timage = Image.open(path)\n",
      "\n",
      "\n",
      "\tinfo = st.session_state['device_state']\n",
      "\n",
      "\n",
      "\t#option rows\n",
      "\t#-----------------------------------------------------------\n",
      "\tcol1, col2 = st.columns(2)\n",
      "\twith col1:\n",
      "\t\texif = image.getexif()\n",
      "\t\tcreation_time = exif.get(3686)\n",
      "\t\tst.image(image)\n",
      "\t\t#https://stackoverflow.com/questions/230/how-to-get-file-creation-modification-date-times-in-python\n",
      "\t\t(mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(path)\n",
      "\t\tst.caption(\"Photo last retreived: %s\" % time.ctime(mtime))\n",
      "\n",
      "\twith col2:\n",
      "\t\tst.header('Status: '+info['led_status'])\n",
      "\t\tst.write('Temperature: ',info['temperature'])\n",
      "\t\tst.write('Humidity:',info['humidity'])\n",
      "\t\tst.button('Refresh')\n",
      "\n",
      "********\n",
      "\n",
      "\tmy_expander = st.expander(label='Environmental Sensing  Control')\n",
      "\twith my_expander:\n",
      "\t\tst.write('---')\n",
      "\t\tst.write('Set variable targets:')\n",
      "\t\ttarg = info['target_temperature']\n",
      "\t\ttarget_temp = st.slider('Temperature:',\n",
      "\t\t\thelp='In o Fahrenheit',\n",
      "\t\t\tmin_value=0, \n",
      "\t\t\tmax_value=100,\n",
      "\t\t\tvalue=int(info['target_temperature']),\n",
      "\t\t\t#on_change=db_utils.set_db_device_attribute_value, \n",
      "\t\t\t#args=[\"target_temperature\",info['target_temperature']],\n",
      "\t\t\t)\n",
      "\t\tif target_temp=targ:\n",
      "\t\t\tif st.button('update',key='temp'):\n",
      "\t\t\t\tst.success('updated :)')\n",
      "\t\t\t\tinfo['target_temperature']=target_temp\n",
      "\t\t\t\tdb_utils.set_db_device_attribute_value(\"target_temperature\",target_temp)\n",
      "\n",
      "********\n",
      "\n",
      "\t\ttarg = info['target_humidity']\n",
      "********\n",
      "\n",
      "\t\ttarget_hum = st.slider('Humidity:',\n",
      "\t\t\thelp='(In % Relative Humidity',\n",
      "\t\t\tmin_value=0, \n",
      "\t\t\tmax_value=100,\n",
      "\t\t\tvalue=int(info['target_humidity']))\n",
      "\n",
      "\t\tif target_hum=targ:\n",
      "\t\t\tif st.button('update',key='hum'):\n",
      "\t\t\t\tst.success('updated :)')\n",
      "\t\t\t\tinfo['target_humidity']=target_hum\n",
      "\t\t\t\tdb_utils.set_db_device_attribute_value(\"target_humidity\",target_hum)\n",
      "\n",
      "\t\t\n",
      "\t\tchoices = st.multiselect('Display Time Series Graph (24hr):',['temperature','humidity'])\n",
      "\n",
      "\t\tif len(choices)>0:\n",
      "\t\t\tif 'temperature' in choices:\n",
      "\t\t\t\tvalues=[]\n",
      "\t\t\t\t#[::-1] reverse the list\n",
      "\t\t\t\tfor i in info['temperature_log'][::-1]:\n",
      "\t\t\t\t\tif i=None:\n",
      "\t\t\t\t\t\tvalues.append(i)\n",
      "\t\t\t\tst.line_chart(values)\n",
      "\t\t\t\t\n",
      "\t\t\tif 'humidity' in choices:\n",
      "\t\t\t\t#st.write(info['humidity_log'])\n",
      "\t\t\t\tvalues=[]\n",
      "\t\t\t\t#[::-1] reverse the list\n",
      "\t\t\t\tfor i in info['humidity_log'][::-1]:\n",
      "\t\t\t\t\tif i=None:\n",
      "\t\t\t\t\t\tvalues.append(i)\n",
      "\t\t\t\tst.line_chart(values)\n",
      "\n",
      "\n",
      "********\n",
      "\n",
      "\tmy_expander = st.expander(label='Automated Process Timers  Intervals')\n",
      "\twith my_expander:\n",
      "\t\tst.write('---')\n",
      "\t\tst.markdown(':sunny:')\n",
      "\t\tst.slider('Sunrise-Sunset', \n",
      "\t\t\tmin_value=0, \n",
      "\t\t\tmax_value=24,\n",
      "\t\t\tvalue=[int(info['time_start_light']),int(info['time_start_dark'])],\n",
      "********\n",
      "\n",
      "\t\t\thelp='Sets times (24hr) for system lights to turn on and off',\n",
      "\t\t\t)\n",
      "\t\t\n",
      "\t\tst.write('---')\n",
      "\t\tst.markdown(':droplet:')\n",
      "\n",
      "********\n",
      "\n",
      "\t\tst.slider('How often should irrigation occur', \n",
      "********\n",
      "\n",
      "\t\t\tmin_value=0, \n",
      "\t\t\tmax_value=24,\n",
      "\t\t\tvalue=int(info['watering_interval']),\n",
      "\t\t\thelp='Time between each watering (in Hours)')\n",
      "\n",
      "********\n",
      "\n",
      "\t\tst.slider('How long should the pump run each time', \n",
      "********\n",
      "\n",
      "\t\t\tmin_value=0, \n",
      "\t\t\tmax_value=24,\n",
      "\t\t\tvalue=int(info['watering_duration']),\n",
      "\t\t\thelp='Duration of each watering (in Seconds)')\n",
      "\n",
      "********\n",
      "\n",
      "\tmy_expander = st.expander(label='Device Settings')\n",
      "\twith my_expander:\n",
      "\n",
      "\t\tst.write('---')\n",
      "\t\tst.warning('Turning off a device will caulse all environmental control and monitoring to cease.')\n",
      "\t\tif st.button('Start/Stop'):\n",
      "\t\t\t#turn on\n",
      "\t\t\tif info['running']==\"0\":\n",
      "\t\t\t\tdb_utils.set_db_device_attribute_value(\"running\",\"1\")\n",
      "\t\t\telse:\n",
      "\t\t\t\tdb_utils.set_db_device_attribute_value(\"running\",\"0\")\n",
      "\n",
      "\t\t#st.write(\"Should Device be Running : \" + str(run_state))\n",
      "\t\t#st.write('Current device state given by \"Status.\" May take a minute for box to adjust into desired mode')\n",
      "\t\tst.write('---')\n",
      "\n",
      "\n",
      "\t\t#[TODO]\n",
      "\t\t#st.warning('Make sure device is deactived. Press once and wait. This may take a while.')\n",
      "\t\t#st.button('Export Data') \n",
      "\n",
      "\t\t#this one should eventually have a check if there even is an update\n",
      "\t\tst.warning('Make sure device is deactived. Press once and wait. This may also take a while.')\n",
      "\t\tif st.button('Update Firmware'):\n",
      "\t\t\tdb_utils.set_db_device_attribute_value(\"awaiting_update\",\"1\")\n",
      "\n",
      "\t\t\n",
      "\t\t#How what is default who resets it\n",
      "\t\t#st.warning('Warning: Resets all configurations and data storage on device to default.')\n",
      "\t\t#st.button('Set to defult') #we should inclue an \"are you sure prompt here lol\"\n",
      "\n",
      "\t\tst.warning('Warning: All current information will be lost')\n",
      "\t\tst.button('Delete Device') #we should inclue an \"are you sure prompt here lol\"\n",
      "\n",
      "#run()\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    code = get_GCJ_code()\n",
    "    \n",
    "    \n",
    "    new_code = code.replace(' ',' SPACE')\n",
    "    #newline\n",
    "    new_code = new_code.replace('\\n',' NEWLINE')\n",
    "    #tab\n",
    "    new_code = new_code.replace('\\t',' TAB')\n",
    "\n",
    "    tokens = tokenizer.encode(new_code,t=str)\n",
    "\n",
    "\n",
    "    wd=20 #window diameter\n",
    "    X_windows = centered_sliding_window(tokens,wd,encode=True)\n",
    "    code, breaks = get_predicted_break_points(X_windows,LSTM_LM_net_trained)\n",
    "\n",
    "    #from code segmentation file\n",
    "    comments_added = insert_comments(code,breaks)\n",
    "    comments_added_decoded = tokenizer.decode(comments_added)\n",
    "    comments_added_token_string = ''.join(comments_added_decoded)\n",
    "    comments_added_token_string = comments_added_token_string.replace('SPACE',' ')\n",
    "    comments_added_token_string = comments_added_token_string.replace('NEWLINE','\\n')\n",
    "    comments_added_token_string = comments_added_token_string.replace('TAB','\\t')\n",
    "    print(comments_added_token_string)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
